<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Joseph T. Ornstein" />

<meta name="date" content="2019-04-26" />

<title>The SRP Package</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<meta name="description" content="Joe Ornstein's Personal Website" />

<link rel="icon" type="image/png" href="images/washu-seal.png" />

<script type="text/javascript" src="js/redirect.js"></script>
<script type="text/javascript" src="js/rmarkdown.js"></script>
<script type="text/javascript" src="js/ga.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="css\rmarkdown.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="rStudioHeader" class="alwaysShrunk">
  <div class="innards bandContent">
    <div>
      <a class="productName" href="index.html">Joe Ornstein</a>
    </div>

    <div id="menu">
      <div id="menuToggler"></div>
      <div id="menuItems">
        <a class="menuItem" href="research.html">Research</a>
        <a class="menuItem" href="teaching.html">Teaching</a>
	<a class="menuItem" href="software.html">Software/Data</a>
        <a class="menuItem" href="CV/ornstein_CV.pdf">CV</a>
      </div>
    </div>
  </div>
</div>

<style type="text/css">
#TOC {
  margin-left: 50px;
  margin-top: 90px;
}
</style>

<script type="text/javascript">
$(".main-container").removeClass("main-container").removeClass("container-fluid").addClass("footerPushDown");
</script>


<div id="pageContent" class="standardPadding">
  <div class="articleBandContent">

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">The SRP Package</h1>
<h4 class="author">Joseph T. Ornstein</h4>
<h4 class="date">2019-04-26</h4>

</div>


<p>SRP is an <code>R</code> package that contains useful functions for implementing multilevel regression and poststratification (MRP) and stacked regression and poststratification (SRP).</p>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>Suppose we want to know how some public opinion varies by subnational unit. But we don’t have surveys that were conducted at the unit-level, only a national-level survey. How can we use the information from the national survey to make inferences about the subnational level? This vignette walks through three techniques for doing so: disaggregation, multilevel regression and poststratification (MRP), and stacked regression and poststratification (SRP). It concludes with an introduction to synthetic poststratification.</p>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>The <code>SRP</code> package is currently available on GitHub. You can install it using the <code>devtools</code> package.</p>
<pre class="r"><code>devtools::install_github(&#39;joeornstein/SRP&#39;)
library(SRP)</code></pre>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<p>The dataset (<code>trainset</code>) contains individual-level data on public opinion and demographic characteristics. It is simulated data, generated from the Monte Carlo in <span class="citation">Ornstein (2019)</span>. It contains the following variables:</p>
<pre class="r"><code>trainset &lt;- SRP::vignetteData

trainset
#&gt; # A tibble: 3,000 x 8
#&gt;         ID      y    x1    x2  unit latitude longitude unit_covariate
#&gt;      &lt;int&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;
#&gt;  1  638233 -2.68      2     1    43    0.663    0.140            2.22
#&gt;  2 1909280  2.01      3     3   128    0.987    0.504            2.64
#&gt;  3 2513825 -4.36      1     2   168    0.752    0.746            2.84
#&gt;  4 2968824 -0.989     2     3   198    0.764    0.190            3.27
#&gt;  5  258017  4.18      1     1    18    0.545    0.897            2.00
#&gt;  6 1252503 -4.54      3     3    84    0.770    0.195            2.43
#&gt;  7 1414783 -3.63      2     2    95    0.518    0.0937           2.47
#&gt;  8  602889  3.56      3     3    41    0.162    0.559            2.20
#&gt;  9  157609  0.271     2     2    11    0.431    0.554            1.93
#&gt; 10 2610832  5.99      4     4   175    0.898    0.932            2.91
#&gt; # ... with 2,990 more rows</code></pre>
<p>The variable <span class="math inline"><em>y</em></span> is our outcome of interest, <span class="math inline"><em>x</em><sub>1</sub></span> and <span class="math inline"><em>x</em><sub>2</sub></span> are individual-level covariates, <code>unit</code> is the subnational unit ID, and <code>latitude</code>, <code>longitude</code>, and <code>unit_covariate</code> are characteristics of the subnational unit.</p>
</div>
<div id="disaggregation" class="section level2">
<h2>Disaggregation</h2>
<p>Disaggregation is the most straightforward method to estimate. Simply take the unit-level means from the national survey. Note, however, that the number of observations within each unit is fairly small. As a result, disaggregation is unlikely to yield good estimates. This is why we adopt a model-based approach.</p>
<pre class="r"><code>disag_estimates &lt;- trainset %&gt;% 
  group_by(unit) %&gt;% 
  summarise(disag_estimate = mean(y),
            num = n())

disag_estimates
#&gt; # A tibble: 200 x 3
#&gt;     unit disag_estimate   num
#&gt;    &lt;int&gt;          &lt;dbl&gt; &lt;int&gt;
#&gt;  1     1          -6.15    14
#&gt;  2     2           2.61    14
#&gt;  3     3          -4.10    16
#&gt;  4     4          -3.45    15
#&gt;  5     5          -3.63    10
#&gt;  6     6          -5.40    21
#&gt;  7     7          -2.74    15
#&gt;  8     8          -2.95    18
#&gt;  9     9          -1.61    15
#&gt; 10    10          -1.48    16
#&gt; # ... with 190 more rows</code></pre>
</div>
<div id="mrp" class="section level2">
<h2>MRP</h2>
<p>Multilevel regression and poststratification (MRP) was introduced by <span class="citation">Gelman and Little (1997)</span> and refined by <span class="citation">Park, Gelman, and Bafumi (2004)</span>. It proceeds in two steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate a multilevel regression, predicting opinion using observed individual-level and unit-level covariates.</li>
<li>Poststratify by taking the mean of each group’s prediction weighted by their frequency in the subnational unit.</li>
</ol>
<p>We can estimate the first-stage regression using the <code>lme4</code> package.</p>
<pre class="r"><code>library(lme4)

model1 &lt;- lmer(y ~ (1|x1) + (1|x2) + unit_covariate + (1|unit), data = trainset)</code></pre>
<p>For the second stage, we need a <strong>poststratification frame</strong>. For the <code>SRP</code> package, it should come in the following format.</p>
<pre class="r"><code>PSFrame &lt;- SRP::vignettePSFrame

PSFrame
#&gt; # A tibble: 3,200 x 7
#&gt;     unit    x1    x2  freq unit_covariate latitude longitude
#&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
#&gt;  1     1     1     1  5482           1.54    0.623    0.0647
#&gt;  2     1     1     2  2497           1.54    0.623    0.0647
#&gt;  3     1     1     3   499           1.54    0.623    0.0647
#&gt;  4     1     1     4    43           1.54    0.623    0.0647
#&gt;  5     1     2     1  2418           1.54    0.623    0.0647
#&gt;  6     1     2     2  1817           1.54    0.623    0.0647
#&gt;  7     1     2     3   603           1.54    0.623    0.0647
#&gt;  8     1     2     4    58           1.54    0.623    0.0647
#&gt;  9     1     3     1   557           1.54    0.623    0.0647
#&gt; 10     1     3     2   590           1.54    0.623    0.0647
#&gt; # ... with 3,190 more rows</code></pre>
<p>Each row reports the empirical frequency for each unique combination of individual-level characteristics, repeated for each subnational unit. For example, the first row reports that there are 5482 individuals with <span class="math inline"><em>x</em><sub>1</sub> = 1</span> and <span class="math inline"><em>x</em><sub>2</sub> = 1</span> in Unit 1.</p>
<p>Once we have both pieces of information – the predictions and the frequencies – poststratification simply requires taking a weighted average, using the <code>poststratify</code> function. Note that this function requires your poststratification frame to have two particular variables:</p>
<ul>
<li><code>unit</code>: the identity of the subnational unit.</li>
<li><code>freq</code>: the empirical frequency for each cell.</li>
</ul>
<pre class="r"><code>pred &lt;- predict(model1, PSFrame, allow.new.levels = T)

mrp_estimates &lt;- poststratify(pred, PSFrame)

mrp_estimates
#&gt; # A tibble: 200 x 2
#&gt;     unit poststratifiedEstimate
#&gt;    &lt;int&gt;                  &lt;dbl&gt;
#&gt;  1     1                  -3.54
#&gt;  2     2                  -1.38
#&gt;  3     3                  -2.72
#&gt;  4     4                  -2.49
#&gt;  5     5                  -2.39
#&gt;  6     6                  -2.96
#&gt;  7     7                  -2.06
#&gt;  8     8                  -2.27
#&gt;  9     9                  -1.76
#&gt; 10    10                  -1.66
#&gt; # ... with 190 more rows</code></pre>
</div>
<div id="srp" class="section level2">
<h2>SRP</h2>
<p>Stacked regression and poststratification (SRP) proceeds in the same fashion as MRP, but the first-stage predictions come from an ensemble model average generated through stacking. See <span class="citation">Ornstein (2019)</span> for technical details.</p>
<p>To start, we must tune and estimate each of the component models separately. The following code estimates a hierarchical linear regression model, LASSO, random forest, KNN, and gradient boosting.</p>
<pre class="r"><code>library(glmnet)
library(ranger)
library(kknn)
library(xgboost)
library(caret)


#Estimate HLM
hlmFormula &lt;- y ~ (1|x1) +  (1|x2) + unit_covariate + (1|unit) 
hlmModel &lt;- lmer(hlmFormula, data = trainset)

#Tune LASSO
lasso_vars &lt;- c(&quot;x1&quot;,&quot;x2&quot;,&quot;unit&quot;,&quot;unit_covariate&quot;)
lasso_factors &lt;- c(&#39;x1&#39;, &#39;x2&#39;, &#39;unit&#39;) #which variables to convert to factors
trainset_lasso &lt;- cleanDataLASSO(trainset, lasso_vars, lasso_factors)$trainset

lassoModel &lt;- cv.glmnet(trainset_lasso, trainset$y, 
                        type.measure = &quot;mse&quot;) 

#Tune KNN
knnFormula &lt;- y ~ x1 + x2 + latitude + longitude + unit_covariate
knn_train &lt;- train.kknn(knnFormula, data=trainset, kmax = 201) #Find best k (LOOCV)
k_best &lt;- knn_train$best.parameters$k

#Tune Random Forest
forestFormula &lt;- y ~ x1 + x2 + latitude + longitude + unit_covariate
forestModel &lt;- ranger(forestFormula, data = trainset)

#Tune GBM
gbm_vars &lt;- c(&quot;x1&quot;,&quot;x2&quot;,&quot;latitude&quot;,&quot;longitude&quot;,&quot;unit_covariate&quot;)
trainset_gbm &lt;- cleanDataGBM(trainset=trainset, gbm_vars=gbm_vars)$trainset
#Create a custom &#39;xgb.DMatrix&#39;. Faster computation
dtrain &lt;- xgb.DMatrix(trainset_gbm, label = trainset$y)

#5-fold cross-validation; pick nrounds that minimizes RMSE
xgb.tune &lt;- xgb.cv(data = dtrain, 
                   booster = &quot;gbtree&quot;,
                   objective = &quot;reg:linear&quot;,
                   eval_metric = &quot;rmse&quot;,
                   eta = 0.02,
                   nrounds = 50 / 0.02, #Lower eta -&gt; more trees
                   nfold = 5, 
                   verbose = F,
                   early_stopping_rounds = 20)

gbmModel &lt;- xgboost(data = dtrain, 
                    booster = &quot;gbtree&quot;,
                    objective = &quot;reg:linear&quot;,
                    eval_metric = &quot;rmse&quot;,
                    eta = 0.02,
                    verbose = F,
                    nrounds = xgb.tune$best_iteration)</code></pre>
<p>Next, we will use the <code>getStackWeights()</code> function to estimate the optimal ensemble model average weights using 5-fold cross-validation.</p>
<pre class="r"><code>stackWeights &lt;- getStackWeights(trainset = trainset,
                                hlmFormula = hlmFormula,
                                lasso_vars = lasso_vars,
                                lasso_factors = lasso_factors,
                                forestFormula = forestFormula,
                                knnFormula = knnFormula, k_best = k_best,
                                gbm_vars = gbm_vars, gbm_factors = NULL, 
                                gbm_params = list(eta = 0.02), gbm_tune = xgb.tune, 
                                nfolds = 5)

stackWeights %&gt;% round(3)
#&gt; [1] 0.321 0.000 0.106 0.000 0.572</code></pre>
<p>Then we can poststratify as before.</p>
<pre class="r"><code>PSFrame_lasso &lt;- cleanDataLASSO(PSFrame, lasso_vars = lasso_vars, lasso_factors = lasso_factors,
                                new_vars_lasso = colnames(trainset_lasso))$trainset
PSFrame_gbm &lt;- cleanDataGBM(PSFrame, gbm_vars = gbm_vars)$trainset

M1 &lt;- predict(hlmModel, PSFrame, allow.new.levels = T)
M2 &lt;- predict(lassoModel, newx = PSFrame_lasso, s = lassoModel$lambda.min)
M3 &lt;- kknn(knnFormula, train = trainset, test = PSFrame, k = k_best)$fitted.values
M4 &lt;- predict(forestModel, PSFrame)$predictions
M5 &lt;- predict(gbmModel, PSFrame_gbm)
M &lt;- cbind(M1,M2,M3,M4,M5) %&gt;% as.matrix

pred &lt;- M %*% stackWeights

#Poststratify
srp_estimates &lt;- poststratify(pred, PSFrame)

head(srp_estimates)
#&gt; # A tibble: 6 x 2
#&gt;    unit poststratifiedEstimate
#&gt;   &lt;int&gt;                  &lt;dbl&gt;
#&gt; 1     1                 -0.178
#&gt; 2     2                  0.803
#&gt; 3     3                 -3.15 
#&gt; 4     4                 -2.96 
#&gt; 5     5                  0.257
#&gt; 6     6                 -2.11</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>Because the data came from a simulation, we also know the true unit-level means. Let’s see how our estimates compare.</p>
<p><img src="srp-vignette_files/figure-html/plots-1.png" width="672" /><img src="srp-vignette_files/figure-html/plots-2.png" width="672" /><img src="srp-vignette_files/figure-html/plots-3.png" width="672" /></p>
</div>
<div id="synthetic-poststratification" class="section level2">
<h2>Synthetic Poststratification</h2>
<p>What if you do not have the joint frequency distribution for all your predictor variables at the subnational level? <span class="citation">Leemann and Wasserfallen (2017)</span> propose a method that instead uses marginal frequency distributions called <strong>synthetic poststratification</strong>. The approach proceeds by multiplying the marginal probabilities to create a <em>synethtic</em> joint distribution, assuming that the predictor variables are statistically independent.</p>
<p>Note that this is a strong assumption. However, if the first-stage model is additively-separable, then both classical and synthetic poststratification produce identical results (see Appendix A in <span class="citation">Ornstein (2019)</span> for the proof). This implies that Multilevel Regression and Synthetic Poststratification (MrsP) can produce <em>strictly</em> superior estimates when the first-stage model is linear-additive, because one can include more predictor variables.</p>
<p>The <code>SRP</code> package provides a function that can generate synthetic poststratification frames, called <code>getSyntheticPSFrame()</code>.</p>
<div id="using-the-function" class="section level3">
<h3>Using the Function</h3>
<p>Suppose you have two (non-synthetic) frequency distributions describing the same population.</p>
<pre class="r"><code>PSFrame1 &lt;- SRP::race
PSFrame2 &lt;- SRP::education

PSFrame1
#&gt; # A tibble: 8 x 3
#&gt;    unit  race  freq
#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;
#&gt; 1     1     1   100
#&gt; 2     1     2   200
#&gt; 3     1     3   300
#&gt; 4     1     4   400
#&gt; 5     2     1   200
#&gt; 6     2     2   100
#&gt; 7     2     3   300
#&gt; 8     2     4   400
PSFrame2
#&gt; # A tibble: 6 x 3
#&gt;    unit education  freq
#&gt;   &lt;int&gt;     &lt;int&gt; &lt;int&gt;
#&gt; 1     1         1   250
#&gt; 2     1         2   300
#&gt; 3     1         3   450
#&gt; 4     2         1   450
#&gt; 5     2         2   350
#&gt; 6     2         3   200</code></pre>
<p>To get the synthetic joint distribution, just call <code>getSyntheticPSFrame()</code>. Note that the resulting output is consistent with the marginal frequency distributions; add up all the observations with race == 1 in and it should yield the same frequency from <code>PSFrame1</code>.</p>
<pre class="r"><code>PSFrame &lt;- getSyntheticPSFrame(PSFrame1, PSFrame2)

PSFrame
#&gt; # A tibble: 24 x 4
#&gt;     unit  race education  freq
#&gt;    &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;dbl&gt;
#&gt;  1     1     1         1   25 
#&gt;  2     1     1         2   30 
#&gt;  3     1     1         3   45.
#&gt;  4     1     2         1   50 
#&gt;  5     1     2         2   60 
#&gt;  6     1     2         3   90.
#&gt;  7     1     3         1   75 
#&gt;  8     1     3         2   90 
#&gt;  9     1     3         3  135 
#&gt; 10     1     4         1  100 
#&gt; # ... with 14 more rows</code></pre>
<p>If you want to generate a synthetic poststratification frame from more than one marginal distribution, simply repeat the process.</p>
<pre class="r"><code>PSFrame3 &lt;- SRP::sex

PSFrame3
#&gt; # A tibble: 4 x 3
#&gt;    unit   sex  freq
#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;
#&gt; 1     1     1   600
#&gt; 2     1     2   400
#&gt; 3     2     1   500
#&gt; 4     2     2   500

PSFrame &lt;- getSyntheticPSFrame(PSFrame, PSFrame3)

PSFrame
#&gt; # A tibble: 48 x 5
#&gt;     unit  race education   sex  freq
#&gt;    &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
#&gt;  1     1     1         1     1   15 
#&gt;  2     1     1         1     2   10.
#&gt;  3     1     1         2     1   18 
#&gt;  4     1     1         2     2   12 
#&gt;  5     1     1         3     1   27.
#&gt;  6     1     1         3     2   18.
#&gt;  7     1     2         1     1   30 
#&gt;  8     1     2         1     2   20.
#&gt;  9     1     2         2     1   36 
#&gt; 10     1     2         2     2   24 
#&gt; # ... with 38 more rows</code></pre>
</div>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-Gelman1997">
<p>Gelman, Andrew, and Thomas C Little. 1997. “Poststratification into Many Categories using Hierachical Logistic Regression.” <em>Survey Methodology</em> 23 (2): 127–35. <a href="https://doi.org/10.1016/j.ins.2011.12.036">https://doi.org/10.1016/j.ins.2011.12.036</a>.</p>
</div>
<div id="ref-Leemann2016">
<p>Leemann, Lucas, and Fabio Wasserfallen. 2017. “Extending the Use and Prediction Precision of Subnational Public Opinion Estimation.” <em>American Journal of Political Science</em> 61 (4): 1003–22.</p>
</div>
<div id="ref-Ornstein2019">
<p>Ornstein, Joseph T. 2019. “Stacked Regression and Poststratification.” <em>Working Paper</em>.</p>
</div>
<div id="ref-Park2004">
<p>Park, David K., Andrew Gelman, and Joseph Bafumi. 2004. “Bayesian multilevel estimation with poststratification: State-level estimates from national polls.” <em>Political Analysis</em> 12 (4): 375–85. <a href="https://doi.org/10.1093/pan/mph024">https://doi.org/10.1093/pan/mph024</a>.</p>
</div>
</div>
</div>

  </div> <!-- articleBandContent -->
</div> <!-- pageContent -->

<div id="rStudioFooter" class="band full">
<div class="bandContent">
  <div id="copyright">© Copyright 2018 Joseph T. Ornstein</div>
  <div id="logos">
    <a href="https://twitter.com/joeornstein" class="footerLogo twitter"></a>
    <a href="https://github.com/joeornstein" class="footerLogo gitHub"></a>
    <a href="https://scholar.google.com/citations?user=HXC86u8AAAAJ&hl=en" class="footerLogo googleScholar"></a>
  </div>
</div>
</div>

<script type="text/javascript" src="js/external-links.js"></script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>


</body>
</html>
